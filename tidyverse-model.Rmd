---
title: "Tidyverse - modeling"
author: "Advanced R"
date: "Thursday May 4, 2017"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```


## Learning goals

1. General framework for data modeling with tidyverse tools

2. Consistent approaches as in data wrangling and visualization


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
load("data/adv-R-twin2.RData")
```


## Task

Model-based summary of feature log-intensities for all proteins in every run

* Model the log-intensities of features for each protein considering feature and run as fixed effects

* Run-level summarization with the fitted model


## Approaches

We will discuss tools to perform modeling/testing in multiple groups through

* iterations

* use of nested data frame


## Normalization

Same as in the previous session

```{r}
twin_dia <- tbl_df(twin_dia) %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    )

med_dia <- twin_dia %>% 
    group_by(sample) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

twin_dia2 <- left_join(twin_dia, med_dia) %>% 
    mutate(
        log2inty_h_cn = log2inty_h + log2inty_adj, 
        log2inty_l_cn = log2inty_l + log2inty_adj
    )

twin_dia2
```


## Use linear model to summarize feature log-intensities of a protein

*[TODO]: add a smaller example (e.g., with 3 runs, 4 features)...*

Model feature log-intensities with fixed effects of run and feature

```{r}
# One protein (A1AG_BOVINE)
a1ag <- twin_dia2 %>% filter(protein == "A1AG_BOVINE")

# Linear model with fixed effects of sample and feature, no intercept
fit <- lm(log2inty_l_cn ~ 0 + sample + feature, data = a1ag)
```

### Extract run effect from the linear model

```{r, eval=FALSE}
summary(fit)
```

```{r}
str(summary(fit))

head(summary(fit)$coefficients)
```

```{r, eval=FALSE}
View(summary(fit)$coefficients)
```

```{r}
fit_coef <- coef(fit)
head(fit_coef)

data_frame(effect = attr(fit_coef, "names"), estimate = unname(fit_coef)) %>% 
    filter(grepl("sample", effect))
```


## Summarize for all proteins with a `for()` loop


### Approach 1

* Loop over proteins

* Fit a linear model for each protein with `lm()`

* Add new results to previous ones in every iteration with `rbind()`

```{r}
# Unique proteins in the dataset
uniq_prot <- levels(twin_dia2$protein)

# Approach 1
t_start <- proc.time()
df_allprot <- NULL
for (i in seq_along(uniq_prot)) {
    # Subset for one protein
    oneprot <- twin_dia2 %>% filter(protein == uniq_prot[i])
    # Fit linear model and extract estimates
    fit <- lm(log2inty_l_cn ~ 0 + sample + feature, data = oneprot)
    fit_coef <- coef(fit)
    # Assemble the result in a data frame
    df_oneprot <- data_frame(
        protein = uniq_prot[i], 
        effect = attr(fit_coef, "names"), 
        estimate = unname(fit_coef)
    ) %>% 
        filter(grepl("sample", effect))
    # Attach new result to those in previous iterations
    df_allprot <- rbind(df_allprot, df_oneprot)
}
(t1 <- proc.time() - t_start)
```

We should avoid this approach as it's not very efficient - in every iteration, R has to copy all the data from previous iterations.


### Approach 2

* Loop over proteins

* Fit a linear model for each protein with `lm()`

* Save results in a list

* Combine the results into a data frame with `dplyr::bind_rows()`


```{r}
# Approach 2
t_start <- proc.time()
list_allprot <- vector("list", length = length(uniq_prot))
for (i in seq_along(uniq_prot)) {
    # Subset for one protein
    oneprot <- twin_dia2 %>% filter(protein == uniq_prot[i])
    # Fit linear model and extract estimates
    fit <- lm(log2inty_l_cn ~ 0 + sample + feature, data = oneprot)
    fit_coef <- coef(fit)
    # Assemble the result in a data frame, and save to the list
    list_allprot[[i]] <- data_frame(
        protein = uniq_prot[i], 
        effect = attr(fit_coef, "names"), 
        estimate = unname(fit_coef)
    ) %>% 
        filter(grepl("sample", effect))
}
df_allprot <- bind_rows(list_allprot)
(t2 <- proc.time() - t_start)
```

The approaches discussed so far have two obvious drawbacks: 

1. The output objects of models are not tidy - it requires additional efforts to reformat the objects and extract summaries of our interest

2. The fitted models are not saved - it requires re-fitting the models to extract additional (unplanned) summaries


## broom

A library that turns model objects into data frames in tidy format with three tidying methods: 

* Extract component-level statistics with `broom::tidy()`: 

* Extract observation-level statistics with `broom::augment()` 

* Extract model-level statistics with `broom::glance()` 

```{r}
library(broom)
?broom
```


### Use broom to tidy output objects of models

```{r}
fit <- lm(log2inty_l_cn ~ 0 + sample + feature, data = a1ag)

# Each row is a coefficient
head(tidy(fit))

# Each row is an observation
head(augment(fit))

# One row for the model
glance(fit)
```


### Approach 3

* Define the analysis unit with `dplyr::group_by()`

* Fit a linear model for each protein with `lm()`

* Extract the estimates with `broom::tidy()` and `dplyr::do()` to summarize the information about each protein


```{r}
# Approach 3
t_start <- proc.time()
twin_dia2 %>% 
    group_by(protein) %>%
    do(tidy(lm(log2inty_l_cn ~ 0 + sample + feature, data = .))) %>% 
    filter(grepl("sample", term))
t3 <- proc.time() - t_start
```

Note that multiple rows are generated within each model. 

`.` is used as an argument placeholder

```{r, eval=FALSE}
# When input is not the first argument of a function
FUN(Y, X)
X %>% FUN(Y, .)

FUN(Y, Z = X)
X %>% FUN(Y, Z = .)
```

It's also possible to save the fitted model for each protein, by saving the modeling output into a new column `fit`: 

```{r}
fit_dia <- twin_dia2 %>% 
    group_by(protein) %>% 
    do(fit = lm(log2inty_l_cn ~ 0 + sample + feature, data = .))
fit_dia
```

Applying the tidying methods on each row of the rowwise data frame: 

```{r, eval=FALSE}
fit_dia %>% tidy(fit)
```


## Nested data frame

Use `tidyr::nest()` to create nested data frame for more general approaches

* One row per group

* New `data` column to store the stratified data, in a list (list-column)

```{r}
nested_dia <- twin_dia2 %>% 
    group_by(protein) %>% 
    nest()
nested_dia
```

Extract/assess data in the list with double brackets `[[]]`

```{r}
# Data of protein A1AG_BOVINE
nested_dia$data[[1]]
```

```{r, eval=FALSE}
# Same as
nested_dia[[1, "data"]]
```


### General split-apply-combine approach

* Nested data frame is an instance of list-columns

* Library purrr provides a set of tools for functional programming (to be discussed in more detail)

* Library broom provides tools to extract model-based summaries in a tidy format


*[TODO]: briefly introduce syntax of `purrr::map()`*

```{r}
# For each protein, fit a linear model with purrr::map()
nested_dia <- nested_dia %>% 
    mutate(fit = map(data, ~ lm(log2inty_l_cn ~ 0 + sample + feature, data = .)))
nested_dia
```

```{r}
# For each fitted model, tidy output object with broom::tidy()
nested_dia <- nested_dia %>% 
    mutate(param = map(fit, tidy))
nested_dia
```

```{r}
head(nested_dia$param[[1]])
```

```{r}
# Unnest data back to the original form
nested_dia %>% unnest(param)
```


### Approach 4

* Created a nested data frame with `dplyr::group_by()` `tidyr::nest()`

* Fit a linear model for each protein with `lm()` and `purrr::map()`

* Extract the estimates for each protein with `broom::tidy()` and `purrr::map()`

* Transform back to the original form with `tidyr::unnest()`

```{r}
# Approach 4
t_start <- proc.time()

# Create nested data frame 
nested_dia <- twin_dia2 %>% 
    group_by(protein) %>% 
    nest()
# Model and tidy output objects
nested_dia <- nested_dia %>% 
    mutate(
        fit = map(data, ~ lm(log2inty_l_cn ~ 0 + sample + feature, data = .)), 
        param = map(fit, tidy)
    )
# Unnest data and additional manipulation
nested_dia %>% unnest(param) %>% 
    filter(grepl("sample", term))
t4 <- proc.time() - t_start
```

A major advantage of Approach 4 is that it creates a very rich structured dataset that can be further explored in a principled way.

```{r}
rbind(t1, t2, t3, t4)
```
