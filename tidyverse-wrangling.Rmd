---
title: "Tidyverse - data wrangling"
author: "Advanced R"
date: "Thursday May 4, 2017"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```


## Learning goal

Efficient data manipulation and transformation in the tidyverse.


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
load("data/adv-R-twin.RData")
```


## Example datasets

Liu et al., Quantitative variability of 342 plasma proteins in a human twin population, *Molecular Systems Biology*, 2015. [PMID: 25652787]

* 232 MS runs of plasma samples:
    - 58 pairs of monozygotic (MZ) and dizygotic (DZ) twins.
    - 2 time points.
    - $58 \times 2 \times 2 = 232$.

* Data acquired with MS workflows of:
    - Data independent acquisition (DIA).
    - Selected reaction monitoring (SRM).

* Subset of the original dataset (with `r length(unique(twin_dia$protein))` proteins by DIA and `r length(unique(twin_srm$protein))` proteins by SRM).

```{r}
str(twin_dia)
```

The two data frames have the same format, containing 9 columns:

* `protein` (chr): protein name.
* `feature` (chr): combination of peptide, precursor charge state, fragment ion, and product charge state, separated by `_`.
* `run` (chr): MS run identifier (R001-R232).
* `pair` (int): pair identifier number (1-58).
* `zygosity` (factor): zygosity (MZ, DZ).
* `subject` (int): subject identifier number (1-116).
* `visit` (int): time of visit (1, 2).
* `intensity_l` (num): integrated feature intensity from light (L) channel.
* `intensity_h` (num): integrated feature intensity from heavy (H, aka reference) channel.

```{r}
head(twin_dia)
head(twin_srm)
```


## Tasks

**Task 1:** normalization of feature intensities, in a way that the median intensity of each run in heavy channel is identical (constant normalization).

**Task 2:** comparison between DIA and SRM datasets, to evaluate their agreement in terms of protein quantification.

We will discuss tools in the tidyverse to address the tasks. In particular, how to tidy data, manipulate and transform data, carry out split-apply-combine approach, and join datasets in a consistent fashion using tidyr and dplyr.


## Helpful conventions for data wrangling

Local data frame `tbl_df()` creates a wrapper of data frame that displays nicely in the console.

```{r}
twin_dia <- tbl_df(twin_dia)
twin_srm <- tbl_df(twin_srm)
```

```{r}
class(twin_dia)
twin_dia
```

`View()` calls the data viewer in RStudio:

```{r, eval=FALSE}
View(twin_dia)
```

The **pipe operator** `%>%` to chain multiple operations: 

```{r, eval=FALSE}
# Equivalent representations
FUN(X, Y)
X %>% FUN(Y)
```

```{r, eval=FALSE}
# Chaining two operations
FUN_2( FUN_1(X, Y), Z )
X %>% FUN_1(Y) %>% FUN_2(Z)
```

When your analysis involves multiple operations, this makes the processing flow clear.

The RStudio keyboard shortcut: Ctrl + Shift + M (Windows), Cmd + Shift + M (Mac).


## Tidy data

In a tidy dataset:

* Each **variable** is saved in its own **column**.

* Each **observation** is saved in its own **row**.

* Each type of observational unit is stored in a single table.

Why tidy data? Tidy data complements R's **vectorized operations**. It is easy to access variables in a tidy dataset, and R will automatically preserve observations as you manipulate variables. 

```{r, out.width=800, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/tidy-why.png')
```

Are the input datasets `twin_dia` and `twin_srm` tidy? Let's look at a few examples with values for 2 proteins (APOA, C1QA) and 3 samples (R001, R002, R003) from the SRM dataset.


```{r, echo=FALSE}
# Making untidy data
td_sub <- tbl_df(twin_srm) %>% select(protein, feature, run, intensity_h, intensity_l) %>% 
    filter(run %in% c("R001", "R002", "R003"), protein %in% c("APOA", "C1QA"))

sub1a <- td_sub %>% select(-intensity_l) %>% spread(run, intensity_h, convert = F)
sub1b <- td_sub %>% select(-intensity_h) %>% spread(run, intensity_l, convert = F)
sub2 <- td_sub %>% gather(key = "label", value = "intensity", intensity_h, intensity_l) %>% 
    mutate(label = ifelse(label == "intensity_h", "heavy", "light")) %>% 
    arrange(protein, feature, run, label)
sub12 <- sub2 %>% spread(key = run, value = intensity)
sub3 <- td_sub %>% unite(intensity_both, intensity_h, intensity_l, sep = "/")
```


```{r}
# Subset for heavy channel
sub1a
# Subset for light channel
sub1b
```

In `sub1a` and `sub1b`, some of the column names (R001, R002, R003) are values of a variable, rather than names of variables.

```{r}
sub2
```

As for `sub2`, people may have different opinions on whether it is tidy based on the basic unit to be processed in the analysis: 

* It is tidy, if you view *a feature in one channel (light or heavy) in a run* as an observation.

* It is not tidy, if you view *a feature in a run* as an observation, which is scattered across two rows.

We'll take the second view.

```{r}
sub12
```

`sub12` is a case with both issues.

```{r}
sub3
```

The `intensity_both` column in `sub3` contains both `intensity_h` and `intensity_l` variables.

## tidyr

A package that helps reshape the layout of datasets.

* Make observations from variables with `tidyr::gather()`.

* Make variables from observations with `tidyr::spread()`.

* Split and merge columns with `tidyr::unite()` and `tidyr::separate()`.


### Use `gather()` to make observations from variables

```{r}
sub1a
```

Collapse multiple columns into two columns:

1. A **key** column that contains the former column names.

2. A **value** column that contains the former column cells.

```{r}
sub1a %>% gather(key = run, value = intensity_h, R001, R002, R003)
```

Apply for both `sub1a` and `sub1b` and merge the results: 

```{r}
tidy1a <- sub1a %>% gather(key = run, value = intensity_h, R001, R002, R003)
tidy1b <- sub1b %>% gather(key = run, value = intensity_l, R001, R002, R003)
left_join(tidy1a, tidy1b)  # merge two parts of the dataset, introduced later 
```


### Use `spread()` to make variables from observations

```{r}
sub2
```

Generate multiple columns from two columns:

1. Each unique value in the **key** column becomes a column name.

2. Each value in the **value** column becomes a cell in the new columns.

```{r}
(tidy2 <- sub2 %>% spread(key = label, value = intensity))
```

In some cases, both `gather()` and `spread()` are needed for data tidying.

```{r}
sub12
```

```{r}
sub12 %>% gather(run, intensity, R001, R002, R003)
tidy12 <- sub12 %>% 
    gather(run, intensity, R001, R002, R003) %>% 
    spread(key = label, value = intensity) %>% 
    rename(intensity_h = heavy, intensity_l = light)
tidy12
```


### Use `separate()` to split a column by a character string separator

```{r}
sub3 %>% separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/")
```

Try to convert to better types using `convert = TRUE`, as in 

```{r, eval=FALSE}
sub3 %>% separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/", convert = TRUE)
```


```{r}
tidy12 %>%
    separate(col = feature, into = c("peptide", "z1", "fragment", "z3"), sep = "_")
```


### Use `unite()` to merge columns into a single column

```{r}
tidy12 %>% 
    separate(col = feature, into = c("peptide", "z1", "fragment", "z3"), sep = "_") %>% 
    unite(col = transition, z1, fragment, z3, sep = "_")
```


## dplyr

A package that helps manipulate and transform tabular data. 

* Reshape a dataset (without changing its content):

    - Rename the columns of a data frame with `dplyr::rename()`.

    - Order rows by values of a column with `dplyr::arrange()`.

* Data manipulation and transformation for a single dataset:

    - Extract existing variables with `dplyr::select()`.

    - Extract existing observations with `dplyr::filter()`.

    - Derive new variables with `dplyr::mutate()`.

    - Make grouped summaries with `dplyr::summarise()` and `dplyr::group_by()`.

* Join datasets:

    - Mutating joins with `dplyr::left_join()`, `dplyr::right_join()`, `dplyr::inner_join()`, `dplyr::full_join()`.

    - Filtering joins `dplyr::semi_join()`, `dplyr::anti_join()`.


### Use `rename()` to rename column

```{r}
# Rename column intensity_h as inty_H, intensity_l as inty_L
twin_dia %>% rename(inty_H = intensity_h, inty_L = intensity_l)
```


### Use `arrange()` to order rows 

```{r}
# Order rows by values of column intensity_l, from low to high
twin_dia %>% arrange(protein, feature, intensity_l)

# Order rows by values of column intensity_l, from high to low
twin_dia %>% arrange(protein, feature, desc(intensity_l))
```


### Use `select()` to extract existing variables

```{r}
# Select columns protein and feature
twin_dia %>% select(protein, feature)

# Exclude column pair
twin_dia %>% select(-pair)

# Select from column feature to column intensity_h
twin_dia %>% select(feature:intensity_h)
```

This is helpful to obtain unique values for particular variables, for example: 

```{r}
twin_dia %>% select(protein, feature) %>% 
    distinct()
```

```{r, eval=FALSE}
# Same as
twin_dia %>% distinct(protein, feature)
```


### Use `filter()` extract existing observations

```{r}
twin_dia %>% filter(!is.na(intensity_h))

# Comma as AND operation
twin_dia %>% filter(!is.na(intensity_h), !is.na(intensity_l))
```

```{r, eval=FALSE}
# Same as 
twin_dia %>% filter(!(is.na(intensity_h) | is.na(intensity_l)))
```


### Use `mutate()` to make new variables

`mutate()` uses **window functions**, functions that take a vector of values and return another vector of values.

```{r}
# Log2 transformation
twin_dia %>% mutate(log2inty_l = log2(intensity_l))

# Use the just generated variables
twin_dia %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l), 
        log2inty_d = log2inty_l - log2inty_h
    )
```


### Use `group_by()` and `summarise()` to make grouped summaries

* `summarise()` changes the unit of analysis by using **summary functions**, functions that take a vector of values and return a single value.

* `group_by()` defines the unit of analysis.

```{r}
# Compute mean, sd and median of values in column intensity_l
twin_dia %>% 
    summarise(
        intensity_ave = mean(intensity_l, na.rm = TRUE), 
        intensity_sd = sd(intensity_l, na.rm = TRUE), 
        intensity_med = median(intensity_l, na.rm = TRUE)
    )
```

```{r}
# Compute mean, sd and median of values in column intensity_l, within each run
twin_dia %>% 
    group_by(run) %>% 
    summarise(
        intensity_ave = mean(intensity_l, na.rm = TRUE), 
        intensity_sd = sd(intensity_l, na.rm = TRUE), 
        intensity_med = median(intensity_l, na.rm = TRUE)
    )
```


### Split-apply-combine approach

`group_by()` + `summarise()` serve as a powerful tool for the split-apply-combine approach. To compute the quantities for constant normalization:

```{r}
# Equalizing medians
twin_dia %>% mutate(log2inty_h = log2(intensity_h)) %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)
```

Now, what's left for Task 1 is to merge this summary to the original data frame.


## Combine datasets

All the figures in this section are from *R for Data Science* by Hadley Wickham and Garrett Grolemund
http://r4ds.had.co.nz/

Consider two datasets `x` and `y`: 

```{r}
x <- data_frame(
    key = c(1, 2, 3), 
    val_x = c("x1", "x2", "x3")
)

y <- data_frame(
    key = c(1, 2, 4), 
    val_y = c("y1", "y2", "y3")
)
```

```{r, out.width=200, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/join-setup.png')
```


### Mutating joins


#### Inner join 

`inner_join(x, y)`: keep only the observations with equal keys.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/join-inner.png')
```

#### Outer joins 

* `left_join(x, y)`: keep all observations in `x` and merge `y` to it.

* `right_join(x, y)`: keep all observations in `y` and merge `x` to it.

* `full_join(x, y)`: keep all observations in `x` and `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/join-outer.png')
```


### Filtering joins

* `semi_join(x, y)`: keep all observations in `x` that have a match in `y`.

* `anti_join(x, y)`: drops all observations in `x` that have a match in `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/join-semi.png')
```

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics('fig/join-anti.png')
```


## Task 1: constant normalization


### Split-apply-combine approach to derive the adjustment 

Use `summarise()` with `group_by()`: 

```{r}
twin_dia <- twin_dia %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    )

med_dia <- twin_dia %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

med_dia
```


### Merge the derived quantities back to the original dataset

```{r}
left_join(twin_dia, med_dia)
```

```{r}
twin_dia2 <- left_join(twin_dia, med_dia) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```

Similarly, for the SRM dataset:

```{r}
twin_srm <- twin_srm %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    ) 

med_srm <- twin_srm %>% group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

twin_srm2 <- left_join(twin_srm, med_srm) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```


### Visualize the result

Boxplot of feature log-intensities in each run, before normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
library(stringr)
twin_dia %>% filter(str_detect(run, str_c(str_pad(1:20, 3, pad = "0"), collapse = "|"))) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Boxplot of feature log-intensities in each run, after normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
twin_dia2 %>% filter(str_detect(run, str_c(str_pad(1:20, 3, pad = "0"), collapse = "|"))) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## Task 2: comparison between DIA and SRM datasets

Evaluate the agreement of protein quantification between DIA and SRM:

* Protein quantification with each dataset using the log of summed feature intensities.

* Merge two datasets.

* Evaluate their agreement.


### Protein quantification with each dataset

Sum up all the normalized feature intensities (in the light channel) for each protein:

```{r}
# Perform log of sum in the DIA dataset
los_dia <- twin_dia2 %>% group_by(run, protein) %>% 
    summarise(sum_dia = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_dia = ifelse(sum_dia == 0, 0, log2(sum_dia)))
los_dia
```

```{r}
# Summarization for the SRM data
los_srm <- twin_srm2 %>% group_by(run, protein) %>% 
    summarise(sum_srm = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_srm = ifelse(sum_srm == 0, 0, log2(sum_srm)))
```


### Merge two datasets

```{r}
# Merge results (with proteins quantified in both)
los_all <- inner_join(los_dia, los_srm)
```

```{r, fig.width=5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point() + geom_smooth(se = FALSE, method = "lm")
```

```{r, fig.width=7.5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point(aes(colour = protein))
```


### Evaluate the agreement

Compute the correlation coefficient:

```{r}
cor(los_all$logsum_dia, los_all$logsum_srm)
```

Compute the correlation per protein:

```{r}
los_all %>% group_by(protein) %>% 
    summarise(correlation = cor(logsum_dia, logsum_srm))
```


## Applying arbitrary operations to grouped data

`summarise()` with `group_by()` is a great tool to apply the split-apply-combine strategy with **summary functions**. To work with arbitrary operations, however, more general tools are needed. 

```{r}
cor.test(los_all$logsum_dia, los_all$logsum_srm)
```

```{r, eval=F}
# This would fail... 
los_all %>% group_by(protein) %>% 
    summarise(corres = cor.test(logsum_dia, logsum_srm))
```


### `group_by()` + `do()`

When the operation `head()` returns multiple rows:

```{r}
twin_dia2 %>% 
    group_by(protein) %>% 
    do(head(., 2))
```

The pronoun `.` is used as an argument placeholder, referring to the group data to be processed. 

If you use named arguments inside `do()`, it creates a **list-column** in the output:

```{r}
twin_dia2 %>% 
    group_by(protein) %>% 
    do(top2 = head(., 2))
```

The list-column is useful to store arbitrary R objects, such as models.

```{r}
los_all %>% group_by(protein) %>% 
    do(fit_cor = cor.test(.$logsum_dia, .$logsum_srm))
```

It creates a list-column `fit_cor` to store the fitted models. We can use double bracket `[[]]` to retrieve the model objects:

```{r}
los_cor <- los_all %>% group_by(protein) %>% 
    do(fit_cor = cor.test(.$logsum_dia, .$logsum_srm))
los_cor$fit_cor[[1]]
```

In the next section, we will learn more techniques to work with list-columns to develop general workflows for both data wrangling and statistical modeling.


## Reference

* R for Data Science, Hadley Wickham and Garrett Grolemund
http://r4ds.had.co.nz/

* RStudio Data Transformation Cheat Sheet
https://www.rstudio.com/resources/cheatsheets/
